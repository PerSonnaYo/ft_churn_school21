{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'data'\n",
    "files = os.listdir(dirname)\n",
    "temp = list(map(lambda name: os.path.join(dirname, name), files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\bank_data_test.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "собираем тренирскую подборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(temp[1], sep=',')\n",
    "test_df = pd.read_csv(temp[0], sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нормализуем некоторые столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "test_df[['REST_AVG_CUR', 'TURNOVER_PAYM', 'REST_AVG_PAYM', 'DEAL_YWZ_IR_MIN', 'DEAL_YWZ_IR_MAX', 'APP_REGISTR_RGN_CODE', 'LDEAL_TENOR_MAX', 'DEAL_YQZ_IR_MAX', 'DEAL_YQZ_IR_MIN', 'LDEAL_TENOR_MIN', 'MAX_PCLOSE_DATE', 'TURNOVER_CC', 'LDEAL_AMT_MONTH', 'AGE']] = scaler.fit_transform(test_df[['REST_AVG_CUR', 'TURNOVER_PAYM', 'REST_AVG_PAYM', 'DEAL_YWZ_IR_MIN', 'DEAL_YWZ_IR_MAX', 'APP_REGISTR_RGN_CODE', 'LDEAL_TENOR_MAX', 'DEAL_YQZ_IR_MAX', 'DEAL_YQZ_IR_MIN', 'LDEAL_TENOR_MIN', 'MAX_PCLOSE_DATE', 'TURNOVER_CC', 'LDEAL_AMT_MONTH', 'AGE']])\n",
    "train_df[['REST_AVG_CUR', 'TURNOVER_PAYM', 'REST_AVG_PAYM', 'DEAL_YWZ_IR_MIN', 'DEAL_YWZ_IR_MAX', 'APP_REGISTR_RGN_CODE', 'LDEAL_TENOR_MAX', 'DEAL_YQZ_IR_MAX', 'DEAL_YQZ_IR_MIN', 'LDEAL_TENOR_MIN', 'MAX_PCLOSE_DATE', 'TURNOVER_CC', 'LDEAL_AMT_MONTH', 'AGE']] = scaler.fit_transform(train_df[['REST_AVG_CUR', 'TURNOVER_PAYM', 'REST_AVG_PAYM', 'DEAL_YWZ_IR_MIN', 'DEAL_YWZ_IR_MAX', 'APP_REGISTR_RGN_CODE', 'LDEAL_TENOR_MAX', 'DEAL_YQZ_IR_MAX', 'DEAL_YQZ_IR_MIN', 'LDEAL_TENOR_MIN', 'MAX_PCLOSE_DATE', 'TURNOVER_CC', 'LDEAL_AMT_MONTH', 'AGE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "текстовые столбцы приводим к числовому формату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family(strin):\n",
    "    if strin == \"FRIEND\" or strin == 'Друг':\n",
    "        return 1\n",
    "    elif strin =='MOTHER' or strin == 'Мать' or strin == 'мать':\n",
    "        return 2\n",
    "    elif strin == 'RELATIVE' or strin == 'Близкий ро':\n",
    "        return 3\n",
    "    elif strin == 'OTHER' or strin == 'Дальний ро':\n",
    "        return 4\n",
    "    elif strin == 'BROTHER' or strin == 'Брат':\n",
    "        return 5\n",
    "    elif strin == 'SISTER' or strin == 'Сестра':\n",
    "        return 6\n",
    "    elif strin == 'FATHER' or strin == 'Отец':\n",
    "        return 7\n",
    "    elif strin == 'DAUGHTER' or strin == 'Дочь':\n",
    "        return 8\n",
    "    elif strin == 'SON' or strin == 'Сын':\n",
    "        return 9\n",
    "    elif strin == 'мать':\n",
    "        return 10\n",
    "    elif strin == 'Жена':\n",
    "        return 11\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alfa1(strin):\n",
    "    if strin == \"M\":\n",
    "        return 1\n",
    "    elif strin =='D':\n",
    "        return 2\n",
    "    elif strin == 'V':\n",
    "        return 3\n",
    "    elif strin == 'T':\n",
    "        return 4\n",
    "    elif strin == 'm':\n",
    "        return 5\n",
    "    elif strin == 'N':\n",
    "        return 6\n",
    "    elif strin == 'v':\n",
    "        return 7\n",
    "    elif strin == 'W':\n",
    "        return 8\n",
    "    elif strin == 'd':\n",
    "        return 9\n",
    "    elif strin == 't':\n",
    "        return 10\n",
    "    elif strin == 'C':\n",
    "        return 11\n",
    "    elif strin == 'w':\n",
    "        return 12\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alfa2(strin):\n",
    "    if strin == \"SO\":\n",
    "        return 1\n",
    "    elif strin =='JO':\n",
    "        return 2\n",
    "    elif strin == 'OTHER':\n",
    "        return 3\n",
    "    elif strin == 'RENT':\n",
    "        return 4\n",
    "    elif strin == 'NPRIVAT':\n",
    "        return 5\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(strin):\n",
    "    if strin == \"SPECIALIST\":\n",
    "        return 1\n",
    "    elif strin =='MANAGER':\n",
    "        return 2\n",
    "    elif strin == 'TOP_MANAGER':\n",
    "        return 3\n",
    "    elif strin == 'SELF_EMPL':\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binar(strin):\n",
    "    if strin == \"N\":\n",
    "        return 0\n",
    "    elif strin =='Y':\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alfa3(strin):\n",
    "    if strin == \"H\":\n",
    "        return 1\n",
    "    elif strin =='SS':\n",
    "        return 2\n",
    "    elif strin == 'UH':\n",
    "        return 3\n",
    "    elif strin == 'S':\n",
    "        return 4\n",
    "    elif strin == 'HH':\n",
    "        return 5\n",
    "    elif strin == 'h':\n",
    "        return 6\n",
    "    elif strin == 's':\n",
    "        return 7\n",
    "    elif strin == 'A':\n",
    "        return 8\n",
    "    elif strin == 'i':\n",
    "        return 9\n",
    "    elif strin == 'US':\n",
    "        return 10\n",
    "    elif strin == 'I':\n",
    "        return 11\n",
    "    elif strin == 'HI':\n",
    "        return 12\n",
    "    elif strin == 'a':\n",
    "        return 13\n",
    "    elif strin == 'e':\n",
    "        return 14\n",
    "    elif strin == 'E':\n",
    "        return 15\n",
    "    elif strin == 'AC':\n",
    "        return 16\n",
    "    elif strin == 'AV':\n",
    "        return 17\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeq(strin):\n",
    "    if strin == \"PRIVATE\":\n",
    "        return 1\n",
    "    elif strin =='STATE':\n",
    "        return 2\n",
    "    elif strin == 'INTER':\n",
    "        return 3\n",
    "    elif strin == 'IP':\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(strin):\n",
    "    if strin == \"102\":\n",
    "        return 1\n",
    "    elif strin =='K01':\n",
    "        return 2\n",
    "    elif strin == 'O01':\n",
    "        return 3\n",
    "    elif strin == '105':\n",
    "        return 4\n",
    "    elif strin == '107':\n",
    "        return 5\n",
    "    elif strin == '103':\n",
    "        return 6\n",
    "    elif strin == '104':\n",
    "        return 7\n",
    "    elif strin == '301':\n",
    "        return 8\n",
    "    elif strin == '101':\n",
    "        return 9\n",
    "    elif strin == '109':\n",
    "        return 10\n",
    "    elif strin == 'M01':\n",
    "        return 11\n",
    "    elif strin == '108':\n",
    "        return 12\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = set(train_df['CLNT_JOB_POSITION'].to_list())\n",
    "box = {}\n",
    "i = 0\n",
    "for s in ss:\n",
    "    if s not in box:\n",
    "        box[s] = i\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job1(strin):\n",
    "    if strin in box:\n",
    "        return box[strin]\n",
    "    else:\n",
    "         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floatinf(df):\n",
    "    df[\"CLNT_TRUST_RELATION\"] = df[\"CLNT_TRUST_RELATION\"].apply(family)\n",
    "    df[\"APP_MARITAL_STATUS\"] = df[\"APP_MARITAL_STATUS\"].apply(alfa1)\n",
    "    df[\"APP_KIND_OF_PROP_HABITATION\"] = df[\"APP_KIND_OF_PROP_HABITATION\"].apply(alfa2)\n",
    "    df[\"CLNT_JOB_POSITION_TYPE\"] = df[\"CLNT_JOB_POSITION_TYPE\"].apply(job)\n",
    "    df[\"APP_DRIVING_LICENSE\"] = df[\"APP_DRIVING_LICENSE\"].apply(binar)\n",
    "    df[\"APP_EDUCATION\"] = df[\"APP_EDUCATION\"].apply(alfa3)\n",
    "    df[\"APP_TRAVEL_PASS\"] = df[\"APP_TRAVEL_PASS\"].apply(binar)\n",
    "    df[\"APP_CAR\"] = df[\"APP_CAR\"].apply(binar)\n",
    "    df[\"APP_POSITION_TYPE\"] = df[\"APP_POSITION_TYPE\"].apply(job)\n",
    "    df[\"APP_EMP_TYPE\"] = df[\"APP_EMP_TYPE\"].apply(typeq)\n",
    "    df[\"APP_COMP_TYPE\"] = df[\"APP_COMP_TYPE\"].apply(typeq)\n",
    "    df[\"PACK\"] = df[\"PACK\"].apply(pack)\n",
    "    df['CLNT_JOB_POSITION'] = df['CLNT_JOB_POSITION'].apply(job1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = floatinf(train_df)\n",
    "test_df = floatinf(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаляем пустые столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['PRC_ACCEPTS_A_EMAIL_LINK',\n",
    "'PRC_ACCEPTS_A_POS',\n",
    "'PRC_ACCEPTS_A_TK',\n",
    "'PRC_ACCEPTS_A_AMOBILE',\n",
    "'PRC_ACCEPTS_TK',\n",
    "'PRC_ACCEPTS_A_MTP',\n",
    "'CNT_ACCEPTS_TK',\n",
    "'PRC_ACCEPTS_A_ATM',\n",
    "'PRC_ACCEPTS_MTP',\n",
    "'CNT_ACCEPTS_MTP'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['PRC_ACCEPTS_A_EMAIL_LINK',\n",
    "'PRC_ACCEPTS_A_POS',\n",
    "'PRC_ACCEPTS_A_TK',\n",
    "'PRC_ACCEPTS_A_AMOBILE',\n",
    "'PRC_ACCEPTS_TK',\n",
    "'PRC_ACCEPTS_A_MTP',\n",
    "'CNT_ACCEPTS_TK',\n",
    "'PRC_ACCEPTS_A_ATM',\n",
    "'PRC_ACCEPTS_MTP',\n",
    "'CNT_ACCEPTS_MTP'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_df.columns:\n",
    "    #df[i] = df[i].astype(np.float32)\n",
    "    if train_df[i].isnull().any():\n",
    "        train_df[i].fillna(train_df[i].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1117: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "for i in test_df.columns:\n",
    "    #df[i] = df[i].astype(np.float32)\n",
    "    if test_df[i].isnull().any():\n",
    "        test_df[i].fillna(test_df[i].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 355190 entries, 0 to 355189\n",
      "Columns: 106 entries, ID to TARGET\n",
      "dtypes: float64(96), int64(10)\n",
      "memory usage: 287.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('ID', inplace=True)\n",
    "test_df.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_PROD_CNT_IL</th>\n",
       "      <th>AMOUNT_RUB_CLO_PRC</th>\n",
       "      <th>APP_REGISTR_RGN_CODE</th>\n",
       "      <th>TURNOVER_DYNAMIC_IL_1M</th>\n",
       "      <th>CNT_TRAN_AUT_TENDENCY1M</th>\n",
       "      <th>SUM_TRAN_AUT_TENDENCY1M</th>\n",
       "      <th>AMOUNT_RUB_SUP_PRC</th>\n",
       "      <th>SUM_TRAN_AUT_TENDENCY3M</th>\n",
       "      <th>CLNT_TRUST_RELATION</th>\n",
       "      <th>REST_DYNAMIC_FDEP_1M</th>\n",
       "      <th>...</th>\n",
       "      <th>REST_DYNAMIC_CC_3M</th>\n",
       "      <th>MED_DEBT_PRC_YWZ</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR3</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_AAVG</th>\n",
       "      <th>LDEAL_DELINQ_PER_MAXYWZ</th>\n",
       "      <th>TURNOVER_DYNAMIC_CC_3M</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR4</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400980</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525062</th>\n",
       "      <td>0</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280316</th>\n",
       "      <td>0</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>0.077876</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CR_PROD_CNT_IL  AMOUNT_RUB_CLO_PRC  APP_REGISTR_RGN_CODE  \\\n",
       "ID                                                                 \n",
       "400980               0            0.000000              0.128378   \n",
       "525062               0            0.059381              0.128378   \n",
       "280316               0            0.070430              0.128378   \n",
       "\n",
       "        TURNOVER_DYNAMIC_IL_1M  CNT_TRAN_AUT_TENDENCY1M  \\\n",
       "ID                                                        \n",
       "400980                     0.0                      0.3   \n",
       "525062                     0.0                      0.3   \n",
       "280316                     0.0                      0.3   \n",
       "\n",
       "        SUM_TRAN_AUT_TENDENCY1M  AMOUNT_RUB_SUP_PRC  SUM_TRAN_AUT_TENDENCY3M  \\\n",
       "ID                                                                             \n",
       "400980                 0.288088            0.000000                 0.724026   \n",
       "525062                 0.288088            0.000333                 0.724026   \n",
       "280316                 0.288088            0.077876                 0.724026   \n",
       "\n",
       "        CLNT_TRUST_RELATION  REST_DYNAMIC_FDEP_1M  ...  REST_DYNAMIC_CC_3M  \\\n",
       "ID                                                 ...                       \n",
       "400980                  2.0                   0.0  ...                 0.0   \n",
       "525062                  2.0                   0.0  ...                 0.0   \n",
       "280316                  2.0                   0.0  ...                 0.0   \n",
       "\n",
       "        MED_DEBT_PRC_YWZ  LDEAL_ACT_DAYS_PCT_TR3  LDEAL_ACT_DAYS_PCT_AAVG  \\\n",
       "ID                                                                          \n",
       "400980               0.0                     0.0                      0.0   \n",
       "525062               1.0                     0.5                      0.5   \n",
       "280316               0.0                     0.0                      0.0   \n",
       "\n",
       "        LDEAL_DELINQ_PER_MAXYWZ  TURNOVER_DYNAMIC_CC_3M  \\\n",
       "ID                                                        \n",
       "400980                      0.0                     0.0   \n",
       "525062                      0.0                     0.0   \n",
       "280316                      0.0                     0.0   \n",
       "\n",
       "        LDEAL_ACT_DAYS_PCT_TR  LDEAL_ACT_DAYS_PCT_TR4  \\\n",
       "ID                                                      \n",
       "400980                    0.0                     0.0   \n",
       "525062                    0.5                     0.5   \n",
       "280316                    0.0                     0.0   \n",
       "\n",
       "        LDEAL_ACT_DAYS_PCT_CURR  TARGET  \n",
       "ID                                       \n",
       "400980                      0.0     NaN  \n",
       "525062                      0.5     NaN  \n",
       "280316                      0.0     NaN  \n",
       "\n",
       "[3 rows x 105 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "test_df[['CLNT_JOB_POSITION', 'CLNT_SETUP_TENOR', 'CLNT_SALARY_VALUE']] = scaler.fit_transform(test_df[['CLNT_JOB_POSITION', 'CLNT_SETUP_TENOR', 'CLNT_SALARY_VALUE']])\n",
    "train_df[['CLNT_JOB_POSITION', 'CLNT_SETUP_TENOR', 'CLNT_SALARY_VALUE']] = scaler.fit_transform(train_df[['CLNT_JOB_POSITION', 'CLNT_SETUP_TENOR', 'CLNT_SALARY_VALUE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe().to_excel('fff1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(50).to_excel('fff.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarin_df1 = train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем список характеристик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CR_PROD_CNT_IL'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'TARGET'\n",
    "features = [x for x in list(tarin_df1.columns) if x != target]\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы использовали последовательную модель, которая представляет собой тип модели, в которой слои укладываются линейно. Первый слой - это слой ввода, где input_dim - это количество функций, а количество выходных единиц равно 16. В скрытом слое мы используем 8 единиц вывода. Наконец, на выходном уровне у нас есть только одна единица вывода, которая возвращает вероятность оттока клиентов. Во входном и скрытом слоях мы использовали функцию активации relu, а на выходе - сигмоидальную функцию активации.\n",
    "# model = Sequential()\n",
    "# model.add(Dense(16, input_dim=len(features), activation='relu'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tarin_df1[features], \n",
    "                                                    tarin_df1[target], \n",
    "                                                    test_size=0.2,\n",
    "                                                   random_state=21, stratify=tarin_df1[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "бейслайн модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for baseline set: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print('AUC for baseline set: %0.4f' % roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищкм наиболее эффектиный метод обучения, через рандом форест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=25, n_estimators=80, random_state=21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc1 = RandomForestClassifier(max_depth=25, n_estimators=80, random_state=21)\n",
    "rfc1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for rfc set: 0.8287\n"
     ]
    }
   ],
   "source": [
    "print('AUC for rfc set: %0.4f' %roc_auc_score(y_test, rfc1.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32,), random_state=21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(32,), random_state=21)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for rfc set: 0.8209\n"
     ]
    }
   ],
   "source": [
    "print('AUC for rfc set: %0.4f' % roc_auc_score(y_test, mlp.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961492786318675"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, rfc1.predict_proba(X_train)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "грид сетка для фореста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=21), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([21, 22, 23, 24]),\n",
       "                         'n_estimators': array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "       67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=21)\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': np.arange(21, 25),\n",
    "              'n_estimators': np.arange(50, 80)}\n",
    "gs = GridSearchCV(rfc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=21), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [22],\n",
       "                         'n_estimators': array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "       67, 68, 69])},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=21)\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [22],\n",
    "              'n_estimators': np.arange(50, 70)}\n",
    "gs = GridSearchCV(rfc, param_grid, scoring='roc_auc', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а вот и самая эффективная сборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 69}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка нам подходит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8312937737551045"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, gs.best_estimator_.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нейросеть на keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы использовали последовательную модель, которая представляет собой тип модели, в которой слои укладываются линейно. Первый слой - это слой ввода, где input_dim - это количество функций, а количество выходных единиц равно 16. В скрытом слое мы используем 8 единиц вывода. Наконец, на выходном уровне у нас есть только одна единица вывода, которая возвращает вероятность оттока клиентов. Во входном и скрытом слоях мы использовали функцию активации relu, а на выходе - сигмоидальную функцию активации.\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2842/2842 [==============================] - 5s 1ms/step - loss: 0.2637 - accuracy: 0.9186\n",
      "Epoch 2/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2558 - accuracy: 0.9186\n",
      "Epoch 3/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2520 - accuracy: 0.9186\n",
      "Epoch 4/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2480 - accuracy: 0.9186\n",
      "Epoch 5/30\n",
      "2842/2842 [==============================] - 3s 962us/step - loss: 0.2443 - accuracy: 0.9186\n",
      "Epoch 6/30\n",
      "2842/2842 [==============================] - 2s 761us/step - loss: 0.2411 - accuracy: 0.9186\n",
      "Epoch 7/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2388 - accuracy: 0.9186\n",
      "Epoch 8/30\n",
      "2842/2842 [==============================] - 3s 996us/step - loss: 0.2368 - accuracy: 0.9186\n",
      "Epoch 9/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2355 - accuracy: 0.9186\n",
      "Epoch 10/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2343 - accuracy: 0.9187\n",
      "Epoch 11/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2331 - accuracy: 0.9187\n",
      "Epoch 12/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2321 - accuracy: 0.9188\n",
      "Epoch 13/30\n",
      "2842/2842 [==============================] - 4s 1ms/step - loss: 0.2313 - accuracy: 0.9188\n",
      "Epoch 14/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2308 - accuracy: 0.9188\n",
      "Epoch 15/30\n",
      "2842/2842 [==============================] - 3s 1ms/step - loss: 0.2303 - accuracy: 0.9189\n",
      "Epoch 16/30\n",
      "2842/2842 [==============================] - 3s 959us/step - loss: 0.2298 - accuracy: 0.9189\n",
      "Epoch 17/30\n",
      "2842/2842 [==============================] - 3s 955us/step - loss: 0.2290 - accuracy: 0.9190\n",
      "Epoch 18/30\n",
      "2842/2842 [==============================] - 3s 896us/step - loss: 0.2290 - accuracy: 0.9190\n",
      "Epoch 19/30\n",
      "2842/2842 [==============================] - 3s 891us/step - loss: 0.2285 - accuracy: 0.9191\n",
      "Epoch 20/30\n",
      "2842/2842 [==============================] - 3s 929us/step - loss: 0.2283 - accuracy: 0.9191\n",
      "Epoch 21/30\n",
      "2842/2842 [==============================] - 3s 919us/step - loss: 0.2280 - accuracy: 0.9191\n",
      "Epoch 22/30\n",
      "2842/2842 [==============================] - 3s 893us/step - loss: 0.2278 - accuracy: 0.9191\n",
      "Epoch 23/30\n",
      "2842/2842 [==============================] - 3s 881us/step - loss: 0.2274 - accuracy: 0.9191\n",
      "Epoch 24/30\n",
      "2842/2842 [==============================] - 3s 925us/step - loss: 0.2274 - accuracy: 0.9191\n",
      "Epoch 25/30\n",
      "2842/2842 [==============================] - 3s 959us/step - loss: 0.2273 - accuracy: 0.9192\n",
      "Epoch 26/30\n",
      "2842/2842 [==============================] - 3s 899us/step - loss: 0.2273 - accuracy: 0.9191\n",
      "Epoch 27/30\n",
      "2842/2842 [==============================] - 3s 881us/step - loss: 0.2271 - accuracy: 0.9193\n",
      "Epoch 28/30\n",
      "2842/2842 [==============================] - 3s 906us/step - loss: 0.2268 - accuracy: 0.9193\n",
      "Epoch 29/30\n",
      "2842/2842 [==============================] - 3s 915us/step - loss: 0.2269 - accuracy: 0.9193\n",
      "Epoch 30/30\n",
      "2842/2842 [==============================] - 3s 893us/step - loss: 0.2267 - accuracy: 0.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fcfceaa488>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220/2220 [==============================] - 1s 556us/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = [x[0] for x in model.predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for keras set: 0.7388\n"
     ]
    }
   ],
   "source": [
    "print('AUC for keras set: %0.4f' % roc_auc_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=21), n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [22],\n",
       "                         'n_estimators': [69]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=21)\n",
    "param_grid = {'criterion': ['entropy'],\n",
    "              'max_depth': [22],\n",
    "              'n_estimators': [69]}\n",
    "gs = GridSearchCV(rfc, param_grid, scoring='roc_auc', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "формируем таблицу результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table:\n",
    "    def __init__(self, model: list):\n",
    "        self.models = model\n",
    "    def form_table(self):\n",
    "        res = []\n",
    "        for i in range(len(self.models)):\n",
    "            if i == 3:\n",
    "                auc = self.models[i][4]\n",
    "            else:\n",
    "                auc = self.add_auc(self.models[i][0])\n",
    "            res.append({'librery': self.models[i][1], 'alorithm': self.models[i][2], 'parametrs': self.models[i][3], 'accuracy': self.add_accuracy(self.models[i][0], i), 'auc': auc})\n",
    "        return(pd.DataFrame(res))\n",
    "    def add_auc(self, model):\n",
    "        try:\n",
    "            test_preds = model.predict_proba(X_test)[:, 1]\n",
    "        except:\n",
    "            test_preds = [x[0] for x in model.predict(X_test)]\n",
    "        return('%0.4f' % roc_auc_score(y_test, test_preds))\n",
    "    def add_accuracy(self, model, i):\n",
    "        print()\n",
    "        # try:\n",
    "            # test_preds = model.predict_proba(X_test)\n",
    "        # except:\n",
    "        print(i)\n",
    "        if i == 4:\n",
    "            print('ddddd')\n",
    "            test_preds = [round(x[0]) for x in model.predict(X_test)]\n",
    "        else:\n",
    "            test_preds = model.predict(X_test)\n",
    "        return('%0.4f' % accuracy_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Table([(rfc1, 'sklearn.RandomForestClassifier', 'A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.', 'max_depth=25, n_estimators=80, random_state=21'), (mlp, 'sclrean.MLPClassifier', 'This model optimizes the log-loss function using LBFGS or stochastic gradient descent', 'hidden_layer_sizes=(32,), random_state=21'), (dummy_clf, 'skleran.DummyClassifier','DummyClassifier makes predictions that ignore the input features. This classifier serves as a simple baseline to compare against other more complex classifiers. The specific behavior of the baseline is selected with the strategy parameter', 'strategy=\"most_frequent\"'), (gs, 'sklearn.GridSearchCV', 'Exhaustive search over specified parameter values for an estimator. Important members are fit, predict', \"'criterion': ['gini', 'entropy'], 'max_depth': [22], 'n_estimators': np.arange(50, 70)\", 0.8312), (model, 'keras.Sequential', 'The sequential API allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs', \"loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "2220/2220 [==============================] - 2s 587us/step\n",
      "\n",
      "4\n",
      "ddddd\n",
      "2220/2220 [==============================] - 1s 579us/step\n"
     ]
    }
   ],
   "source": [
    "fin_df = g.form_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>librery</th>\n",
       "      <th>alorithm</th>\n",
       "      <th>parametrs</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn.RandomForestClassifier</td>\n",
       "      <td>A random forest is a meta estimator that fits ...</td>\n",
       "      <td>max_depth=25, n_estimators=80, random_state=21</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sclrean.MLPClassifier</td>\n",
       "      <td>This model optimizes the log-loss function usi...</td>\n",
       "      <td>hidden_layer_sizes=(32,), random_state=21</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skleran.DummyClassifier</td>\n",
       "      <td>DummyClassifier makes predictions that ignore ...</td>\n",
       "      <td>strategy=\"most_frequent\"</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn.GridSearchCV</td>\n",
       "      <td>Exhaustive search over specified parameter val...</td>\n",
       "      <td>'criterion': ['gini', 'entropy'], 'max_depth':...</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keras.Sequential</td>\n",
       "      <td>The sequential API allows you to create models...</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.8141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          librery  \\\n",
       "0  sklearn.RandomForestClassifier   \n",
       "1           sclrean.MLPClassifier   \n",
       "2         skleran.DummyClassifier   \n",
       "3            sklearn.GridSearchCV   \n",
       "4                keras.Sequential   \n",
       "\n",
       "                                            alorithm  \\\n",
       "0  A random forest is a meta estimator that fits ...   \n",
       "1  This model optimizes the log-loss function usi...   \n",
       "2  DummyClassifier makes predictions that ignore ...   \n",
       "3  Exhaustive search over specified parameter val...   \n",
       "4  The sequential API allows you to create models...   \n",
       "\n",
       "                                           parametrs accuracy     auc  \n",
       "0     max_depth=25, n_estimators=80, random_state=21   0.9193  0.8295  \n",
       "1          hidden_layer_sizes=(32,), random_state=21   0.9167  0.8209  \n",
       "2                           strategy=\"most_frequent\"   0.9186  0.5000  \n",
       "3  'criterion': ['gini', 'entropy'], 'max_depth':...   0.9194  0.8312  \n",
       "4  loss='binary_crossentropy', optimizer='adam', ...   0.9191  0.8141  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "формируем ксв файл для тестовой таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train = test_df.drop(['TARGET'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "400980    1\n",
       "525062    0\n",
       "280316    0\n",
       "496066    0\n",
       "375031    0\n",
       "         ..\n",
       "175305    0\n",
       "275016    0\n",
       "277398    0\n",
       "469164    0\n",
       "397854    1\n",
       "Name: predict, Length: 88798, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gs.best_estimator_.predict(xx_train)\n",
    "# csv_df1['predict'] = pred\n",
    "xx_train['predict'] = pred\n",
    "xx_train\n",
    "xy_train = xx_train['predict']\n",
    "xy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train.to_csv('data/new_test.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.asarray(X_train).astype('float32')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c2dc7f55a4afb133f9671f18548a683b80d7f864af89313bd9839ac682f147f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
